{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ruprompts[hydra]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will train a prompt for style transfer task using the `ruprompts-train` entrypoint. As an example task we will take the [RUSSE 2022 detoxification competition](https://github.com/skoltech-nlp/russe_detox_2022). Let's download the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/skoltech-nlp/russe_detox_2022/main/data/input/train.tsv\n",
    "!wget https://raw.githubusercontent.com/skoltech-nlp/russe_detox_2022/main/data/input/dev.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ruprompts-train` entrypoint is a Hydra application. See the [corresponding section in docs](https://ai-forever.github.io/ru-prompts/hydra/) for details. Also see the section about [config structure](https://ai-forever.github.io/ru-prompts/hydra/config/) for available group options and parameters.\n",
    "\n",
    "Here is a brief explanation of the parameters selected in the below cell:\n",
    "  - `task=text2text` - selects the default model and preprocessing\n",
    "  - `training.run_name=detox-russe` - the run name to be used if WandB is installed and enabled\n",
    "  - `task.task_name=detox` - the task name used to group task workdirs\n",
    "  - `prompt_provider=tensor` - TensorPromptProvider\n",
    "  - `prompt_format.template='\"<P*60>{toxic_comment}<P*20>\"'` - our prompt will contain the prefix of 60 tokens and infix of 20 tokens\n",
    "  - `training.learning_rate=0.1`, `scheduler=linear_schedule_with_warmup` - optimization parameters\n",
    "  - `+dataset=from_tsv` - selects an option for loading the dataset from local TSV files\n",
    "  - `dataset.data_files.train=/content/train.tsv` - defines the training file\n",
    "  - `dataset.data_files.validation=/content/dev.tsv` - defines the validation file\n",
    "  - `preprocessing.target_field=neutral_comment1` - selects the dataset field to be used as target\n",
    "  - `preprocessing.max_tokens=1000` - defines the max length of training sequences in tokens, including the target sequence\n",
    "  - `preprocessing.truncation_field=toxic_comment` - defines the field to be truncated if the training sequence exceeds `max_tokens`\n",
    "  - `training.report_to=tensorboard` - reports logs locally\n",
    "  - callbacks: \n",
    "    - `freeze_transformer_unfreeze_prompt` - makes only prompt provider's parameters trainable\n",
    "    - `reduce_checkpoint` - reduces the checkpoint size after each saving by leaving only prompt provider's weights there\n",
    "    - `save_pretrained_prompt` - saves the prompt as pretrained in each checkpoint folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ruprompts-train \\\n",
    "    task=text2text \\\n",
    "    training.run_name=detox-russe \\\n",
    "    task.task_name=detox \\\n",
    "    prompt_provider=tensor \\\n",
    "    prompt_format.template='\"<P*60>{toxic_comment}<P*20>\"' \\\n",
    "    training.learning_rate=0.1 \\\n",
    "    scheduler=linear_schedule_with_warmup \\\n",
    "    +dataset=from_tsv \\\n",
    "    dataset.data_files.train=/content/train.tsv \\\n",
    "    dataset.data_files.validation=/content/dev.tsv \\\n",
    "    preprocessing.target_field=neutral_comment1 \\\n",
    "    preprocessing.truncation_field=toxic_comment \\\n",
    "    preprocessing.max_tokens=1000 \\\n",
    "    callbacks=[freeze_transformer_unfreeze_prompt,reduce_checkpoint,save_pretrained_prompt] \\\n",
    "    training.report_to=tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the `save_pretrained_prompt` callback is selected, you can load the current prompt from any checkpoint by running something like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ruprompts import Prompt\n",
    "\n",
    "prompt = Prompt.from_pretrained(\"./outputs/debug/detox/20211231_235959/checkpoint-1500\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prompt can then be used for inference just as that loaded from HF Hub.\n",
    "\n",
    "To upload the trained prompt to hub, use the `push_to_hub` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.push_to_hub(\"prompt_backbone_task\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
